{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16263173",
   "metadata": {},
   "source": [
    "\n",
    "## PARTE 0: CONFIGURAÇÃO DO AMBIENTE\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c6b7d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Ambiente configurado e bibliotecas importadas com sucesso!\n",
      "Versão do Pandas: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# 1. Instalação de bibliotecas usando o comando mágico %pip\n",
    "# Garante que a instalação ocorra no kernel correto do notebook.\n",
    "%pip install -q pandas numpy pyarrow fastparquet matplotlib seaborn\n",
    "\n",
    "# 2. Importação das bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 3. Configuração de visualização do Pandas\n",
    "# Garante que todas as colunas de um DataFrame sejam exibidas\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Configura o estilo dos gráficos para um visual mais agradável\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "print(\"Ambiente configurado e bibliotecas importadas com sucesso!\")\n",
    "print(f\"Versão do Pandas: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47466de7",
   "metadata": {},
   "source": [
    "\n",
    "## PARTE 1: CARGA E ESTRUTURAÇÃO DO SINASC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e286262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a carga dos dados do SINASC...\n",
      "Encontrados 984 arquivos Parquet.\n",
      "Exemplo de caminhos encontrados:\n",
      "['sinasc_2020_2022/DNSP2022/part-00001-bd6c59fe-baea-40ee-a750-b5ab8e63d89a-c000.gz.parquet', 'sinasc_2020_2022/DNSP2022/part-00003-bd6c59fe-baea-40ee-a750-b5ab8e63d89a-c000.gz.parquet', 'sinasc_2020_2022/DNSP2022/part-00010-bd6c59fe-baea-40ee-a750-b5ab8e63d89a-c000.gz.parquet']\n",
      "\n",
      "Dados do SINASC carregados e consolidados com sucesso!\n",
      "Total de registros no DataFrame final: 3999785\n",
      "Total de colunas: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODMUNNASC</th>\n",
       "      <th>LOCNASC</th>\n",
       "      <th>CODMUNRES</th>\n",
       "      <th>DTNASC</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>RACACOR</th>\n",
       "      <th>PESO</th>\n",
       "      <th>IDADEMAE</th>\n",
       "      <th>ESTCIVMAE</th>\n",
       "      <th>ESCMAE</th>\n",
       "      <th>GRAVIDEZ</th>\n",
       "      <th>CONSULTAS</th>\n",
       "      <th>RACACORMAE</th>\n",
       "      <th>DTNASCMAE</th>\n",
       "      <th>GESTACAO</th>\n",
       "      <th>SEMAGESTAC</th>\n",
       "      <th>CONSPRENAT</th>\n",
       "      <th>PARTO</th>\n",
       "      <th>CODESTAB</th>\n",
       "      <th>ANO_COLETA</th>\n",
       "      <th>UF_COLETA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355240</td>\n",
       "      <td>1</td>\n",
       "      <td>355240</td>\n",
       "      <td>30032022</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2600</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>19021989</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>05</td>\n",
       "      <td>2</td>\n",
       "      <td>2083981</td>\n",
       "      <td>2022</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>355030</td>\n",
       "      <td>1</td>\n",
       "      <td>355030</td>\n",
       "      <td>29062022</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3800</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>03061986</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>7711980</td>\n",
       "      <td>2022</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>355710</td>\n",
       "      <td>1</td>\n",
       "      <td>355710</td>\n",
       "      <td>21062022</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3035</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22021986</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2081377</td>\n",
       "      <td>2022</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355210</td>\n",
       "      <td>1</td>\n",
       "      <td>355210</td>\n",
       "      <td>29042022</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3420</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18041988</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>2079704</td>\n",
       "      <td>2022</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355370</td>\n",
       "      <td>1</td>\n",
       "      <td>355370</td>\n",
       "      <td>27062022</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2880</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>02101999</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2078295</td>\n",
       "      <td>2022</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CODMUNNASC LOCNASC CODMUNRES    DTNASC SEXO RACACOR  PESO IDADEMAE  \\\n",
       "0    355240        1   355240   30032022    2       4  2600       33   \n",
       "1    355030        1   355030   29062022    2       4  3800       36   \n",
       "2    355710        1   355710   21062022    2       1  3035       36   \n",
       "3    355210        1   355210   29042022    2       1  3420       34   \n",
       "4    355370        1   355370   27062022    1       4  2880       22   \n",
       "\n",
       "  ESTCIVMAE ESCMAE GRAVIDEZ CONSULTAS RACACORMAE DTNASCMAE GESTACAO  \\\n",
       "0         1      4        1         3          4  19021989        4   \n",
       "1         2      3        1         4          4  03061986        5   \n",
       "2         2      4        1         4          1  22021986        5   \n",
       "3         1      5        1         2          1  18041988        5   \n",
       "4         1      4        1         4          4  02101999        5   \n",
       "\n",
       "  SEMAGESTAC CONSPRENAT PARTO CODESTAB  ANO_COLETA UF_COLETA  \n",
       "0         36         05     2  2083981        2022        SP  \n",
       "1         41         16     1  7711980        2022        SP  \n",
       "2         38         10     2  2081377        2022        SP  \n",
       "3         38         03     2  2079704        2022        SP  \n",
       "4         38         11     2  2078295        2022        SP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1.1 Carregando os dados do SINASC (Nascidos Vivos) ---\n",
    "print(\"Iniciando a carga dos dados do SINASC...\")\n",
    "\n",
    "# ETAPA 1: Encontrar todos os caminhos dos arquivos .parquet\n",
    "# O padrão 'sinasc_2020_2022/**/*.parquet' busca recursivamente em todas as subpastas.\n",
    "parquet_path = 'sinasc_2020_2022/**/*.parquet'\n",
    "list_parqutet_files = glob.glob(parquet_path, recursive=True)\n",
    "print(f\"Encontrados {len(list_parqutet_files)} arquivos Parquet.\")\n",
    "# Vamos exibir os 3 primeiros caminhos para verificar se estão corretos.\n",
    "print(\"Exemplo de caminhos encontrados:\")\n",
    "print(list_parqutet_files[:3])\n",
    "\n",
    "# ETAPA 2: Iterar, ler cada arquivo, extrair metadados e armazenar em uma lista\n",
    "list_dfs = []\n",
    "\n",
    "for file_path in list_parqutet_files:\n",
    "    temp_df = pd.read_parquet(file_path)   # Lê o arquivo Parquet em um DataFrame temporário\n",
    "    path_parts = file_path.split(os.sep) # Divide o caminho em partes\n",
    "    dir_name = path_parts[-2]  # Nome do diretório (ano)\n",
    "    year_collect = int(dir_name[-4:]) # Extrai o ano dos últimos 4 caracteres\n",
    "    uf_collect = dir_name[2:4]   # Extrai a UF dos caracteres na posição 2 e 3\n",
    "\n",
    "    temp_df['ANO_COLETA'] = year_collect  # Adiciona a coluna do ano de coleta\n",
    "    temp_df['UF_COLETA'] = uf_collect    # Adiciona a coluna da UF de coleta\n",
    "\n",
    "    list_dfs.append(temp_df)  # Adiciona o DataFrame temporário à lista\n",
    "\n",
    "# ETAPA 3: Concatenar todos os DataFrames em um único DataFrame\n",
    "if list_dfs:\n",
    "    df_sinasc = pd.concat(list_dfs, ignore_index=True)\n",
    "    print(\"\\nDados do SINASC carregados e consolidados com sucesso!\")\n",
    "    print(f\"Total de registros no DataFrame final: {len(df_sinasc)}\")\n",
    "    print(f\"Total de colunas: {len(df_sinasc.columns)}\")\n",
    "\n",
    "    display(df_sinasc.head())\n",
    "else:\n",
    "    print(\"\\nErro: Nenhum DataFrame foi carregado. Verifique os arquivos Parquet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb38f9e8",
   "metadata": {},
   "source": [
    "## ESTRATÉGIA DE OTIMIZAÇÃO: REDUÇÃO DO USO DE MEMÓRIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c037045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Função 'optimize_memory_usage' definida com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Função para reduzir o uso de memória dos DataFrames.\n",
    "\n",
    "def optimize_memory_usage(df, print_log=True):\n",
    "    \"\"\"\n",
    "    Itera sobre todas as colunas de um DataFrame e modifica o tipo de dado\n",
    "    para o formato mais eficiente em memória.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): O DataFrame a ser otimizado.\n",
    "    print_log (bool): Se True, imprime o log da redução de memória.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: O DataFrame otimizado.\n",
    "    \"\"\"\n",
    "    if print_log:\n",
    "        # Calcula o uso de memória inicial\n",
    "        mem_usage_before = df.memory_usage(deep=True).sum() / 1024**2\n",
    "        print(f\"Uso de memória inicial: {mem_usage_before:.2f} MB\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        # Verifica se a coluna é numérica (inteiro ou float)\n",
    "        if pd.api.types.is_numeric_dtype(col_type) and not pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            # Se for do tipo inteiro, tenta diminuir para o menor inteiro possível\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            # Se for do tipo float, tenta diminuir para um float menor\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        \n",
    "        # Se a coluna for de texto (object)\n",
    "        elif col_type == 'object':\n",
    "            # Se a proporção de valores únicos for baixa, converte para 'category'\n",
    "            # O tipo 'category' é muito mais eficiente para strings repetidas (ex: 'UF_COLETA')\n",
    "            if df[col].nunique() / len(df[col]) < 0.5:\n",
    "                df[col] = df[col].astype('category')\n",
    "    \n",
    "    if print_log:\n",
    "        # Calcula o uso de memória final\n",
    "        mem_usage_after = df.memory_usage(deep=True).sum() / 1024**2\n",
    "        reduction = 100 * (mem_usage_before - mem_usage_after) / mem_usage_before\n",
    "        print(f\"Uso de memória final: {mem_usage_after:.2f} MB ({reduction:.2f}% de redução)\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "print(\"Função 'optimize_memory_usage' definida com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74360e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otimizando df_sinasc...\n",
      "Uso de memória inicial: 1085.42 MB\n",
      "Uso de memória final: 223.78 MB (79.38% de redução)\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a otimização no df_sinasc\n",
    "\n",
    "print(\"Otimizando df_sinasc...\")\n",
    "# Chamamos a função e sobrescrevemos a variável original com a versão otimizada\n",
    "df_sinasc = optimize_memory_usage(df_sinasc)\n",
    "\n",
    "# Faremos o mesmo para o df_ibge_cities quando o carregarmos.\n",
    "# Por enquanto, garantimos que o df_sinasc está leve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c6e466",
   "metadata": {},
   "source": [
    "\n",
    "## PARTE 1.2: CARREGANDO DADOS DO IBGE E ENRIQUECENDO O DF_SINASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5d934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando e otimizando a base de cidades e estados do IBGE\n",
      "\n",
      "Criando dicionários de tradução para cidades e estados\n",
      "Dicionários criados.\n",
      "\n",
      "Limpando chaves do df_sinasc e aplicando .map() para enriquecer os dados\n",
      "Enriquecimento e limpeza da CODMUNNASC concluído.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODMUNNASC</th>\n",
       "      <th>LOCNASC</th>\n",
       "      <th>CODMUNRES</th>\n",
       "      <th>DTNASC</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>RACACOR</th>\n",
       "      <th>PESO</th>\n",
       "      <th>IDADEMAE</th>\n",
       "      <th>ESTCIVMAE</th>\n",
       "      <th>ESCMAE</th>\n",
       "      <th>GRAVIDEZ</th>\n",
       "      <th>CONSULTAS</th>\n",
       "      <th>RACACORMAE</th>\n",
       "      <th>DTNASCMAE</th>\n",
       "      <th>GESTACAO</th>\n",
       "      <th>SEMAGESTAC</th>\n",
       "      <th>CONSPRENAT</th>\n",
       "      <th>PARTO</th>\n",
       "      <th>CODESTAB</th>\n",
       "      <th>ANO_COLETA</th>\n",
       "      <th>UF_COLETA</th>\n",
       "      <th>COD_UF_NASC</th>\n",
       "      <th>NOME_UF_NASC</th>\n",
       "      <th>SIGLA_UF_NASC</th>\n",
       "      <th>NOME_MUNIC_NASC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451070</th>\n",
       "      <td>230440</td>\n",
       "      <td>1</td>\n",
       "      <td>230440</td>\n",
       "      <td>11092020</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3640</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>19011993</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>07</td>\n",
       "      <td>1</td>\n",
       "      <td>2651351</td>\n",
       "      <td>2020</td>\n",
       "      <td>CE</td>\n",
       "      <td>23</td>\n",
       "      <td>Ceará</td>\n",
       "      <td>CE</td>\n",
       "      <td>Fortaleza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867709</th>\n",
       "      <td>410580</td>\n",
       "      <td>1</td>\n",
       "      <td>410580</td>\n",
       "      <td>22122020</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3100</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>06081998</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2753332</td>\n",
       "      <td>2020</td>\n",
       "      <td>PR</td>\n",
       "      <td>41</td>\n",
       "      <td>Paraná</td>\n",
       "      <td>PR</td>\n",
       "      <td>Colombo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481706</th>\n",
       "      <td>500660</td>\n",
       "      <td>1</td>\n",
       "      <td>500660</td>\n",
       "      <td>09122021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2435</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15101996</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>09</td>\n",
       "      <td>2</td>\n",
       "      <td>2651610</td>\n",
       "      <td>2021</td>\n",
       "      <td>MS</td>\n",
       "      <td>50</td>\n",
       "      <td>Mato Grosso do Sul</td>\n",
       "      <td>MS</td>\n",
       "      <td>Ponta Porã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614224</th>\n",
       "      <td>220770</td>\n",
       "      <td>1</td>\n",
       "      <td>220770</td>\n",
       "      <td>27122021</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3860</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18031998</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8015899</td>\n",
       "      <td>2021</td>\n",
       "      <td>PI</td>\n",
       "      <td>22</td>\n",
       "      <td>Piauí</td>\n",
       "      <td>PI</td>\n",
       "      <td>Parnaíba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3304920</th>\n",
       "      <td>510704</td>\n",
       "      <td>1</td>\n",
       "      <td>510700</td>\n",
       "      <td>28012021</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3070</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>22031996</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>09</td>\n",
       "      <td>2</td>\n",
       "      <td>3636364</td>\n",
       "      <td>2021</td>\n",
       "      <td>MT</td>\n",
       "      <td>51</td>\n",
       "      <td>Mato Grosso</td>\n",
       "      <td>MT</td>\n",
       "      <td>Primavera do Leste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411407</th>\n",
       "      <td>355030</td>\n",
       "      <td>1</td>\n",
       "      <td>355030</td>\n",
       "      <td>13072020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2515</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>26051987</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>08</td>\n",
       "      <td>2</td>\n",
       "      <td>2058391</td>\n",
       "      <td>2020</td>\n",
       "      <td>SP</td>\n",
       "      <td>35</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>São Paulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902532</th>\n",
       "      <td>521800</td>\n",
       "      <td>1</td>\n",
       "      <td>521800</td>\n",
       "      <td>30062022</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3230</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>09031984</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>06</td>\n",
       "      <td>2</td>\n",
       "      <td>8001510</td>\n",
       "      <td>2022</td>\n",
       "      <td>GO</td>\n",
       "      <td>52</td>\n",
       "      <td>Goiás</td>\n",
       "      <td>GO</td>\n",
       "      <td>Porangatu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009881</th>\n",
       "      <td>520870</td>\n",
       "      <td>1</td>\n",
       "      <td>520870</td>\n",
       "      <td>27022021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3480</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>26121999</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>09</td>\n",
       "      <td>1</td>\n",
       "      <td>2338564</td>\n",
       "      <td>2021</td>\n",
       "      <td>GO</td>\n",
       "      <td>52</td>\n",
       "      <td>Goiás</td>\n",
       "      <td>GO</td>\n",
       "      <td>Goiânia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970526</th>\n",
       "      <td>520870</td>\n",
       "      <td>1</td>\n",
       "      <td>520870</td>\n",
       "      <td>04112021</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2460</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19061984</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2518392</td>\n",
       "      <td>2021</td>\n",
       "      <td>GO</td>\n",
       "      <td>52</td>\n",
       "      <td>Goiás</td>\n",
       "      <td>GO</td>\n",
       "      <td>Goiânia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156437</th>\n",
       "      <td>353070</td>\n",
       "      <td>1</td>\n",
       "      <td>353070</td>\n",
       "      <td>02052021</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2618</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>16021995</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2096463</td>\n",
       "      <td>2021</td>\n",
       "      <td>SP</td>\n",
       "      <td>35</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>Mogi Guaçu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CODMUNNASC LOCNASC CODMUNRES    DTNASC SEXO RACACOR  PESO IDADEMAE  \\\n",
       "451070       230440       1   230440   11092020    1       4  3640       27   \n",
       "1867709      410580       1   410580   22122020    2       1  3100       22   \n",
       "3481706      500660       1   500660   09122021    1       1  2435       25   \n",
       "2614224      220770       1   220770   27122021    1       4  3860       23   \n",
       "3304920      510704       1   510700   28012021    2       4  3070       24   \n",
       "2411407      355030       1   355030   13072020    1       1  2515       33   \n",
       "3902532      521800       1   521800   30062022    1       4  3230       38   \n",
       "2009881      520870       1   520870   27022021    1       1  3480       21   \n",
       "1970526      520870       1   520870   04112021    2       1  2460       37   \n",
       "2156437      353070       1   353070   02052021    2       4  2618       26   \n",
       "\n",
       "        ESTCIVMAE ESCMAE GRAVIDEZ CONSULTAS RACACORMAE DTNASCMAE GESTACAO  \\\n",
       "451070          1      3        1         4          4  19011993        5   \n",
       "1867709         1      4        1         4          1  06081998        5   \n",
       "3481706         5      4        2         4          1  15101996        5   \n",
       "2614224         5      4        1         4          4  18031998        5   \n",
       "3304920         2      5        1         4          4  22031996        5   \n",
       "2411407         2      5        1         4          1  26051987        4   \n",
       "3902532         1      5        1         3          4  09031984        5   \n",
       "2009881         2      5        1         4          1  26121999        5   \n",
       "1970526         2      5        1         4          1  19061984        5   \n",
       "2156437         2      4        1         4          4  16021995        5   \n",
       "\n",
       "        SEMAGESTAC CONSPRENAT PARTO CODESTAB  ANO_COLETA UF_COLETA  \\\n",
       "451070          38         07     1  2651351        2020        CE   \n",
       "1867709         39         13     1  2753332        2020        PR   \n",
       "3481706         37         09     2  2651610        2021        MS   \n",
       "2614224         41         10     1  8015899        2021        PI   \n",
       "3304920         38         09     2  3636364        2021        MT   \n",
       "2411407         35         08     2  2058391        2020        SP   \n",
       "3902532         39         06     2  8001510        2022        GO   \n",
       "2009881         37         09     1  2338564        2021        GO   \n",
       "1970526         37         10     2  2518392        2021        GO   \n",
       "2156437         40         12     1  2096463        2021        SP   \n",
       "\n",
       "         COD_UF_NASC        NOME_UF_NASC SIGLA_UF_NASC     NOME_MUNIC_NASC  \n",
       "451070            23               Ceará            CE           Fortaleza  \n",
       "1867709           41              Paraná            PR             Colombo  \n",
       "3481706           50  Mato Grosso do Sul            MS          Ponta Porã  \n",
       "2614224           22               Piauí            PI            Parnaíba  \n",
       "3304920           51         Mato Grosso            MT  Primavera do Leste  \n",
       "2411407           35           São Paulo            SP           São Paulo  \n",
       "3902532           52               Goiás            GO           Porangatu  \n",
       "2009881           52               Goiás            GO             Goiânia  \n",
       "1970526           52               Goiás            GO             Goiânia  \n",
       "2156437           35           São Paulo            SP          Mogi Guaçu  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrames auxiliares liberados da memória\n"
     ]
    }
   ],
   "source": [
    "# --- 1.2.1 Carregando e Otimizando os dados do IBGE (.map() strategy)\n",
    "\n",
    "print(\"Carregando e otimizando a base de cidades e estados do IBGE\")\n",
    "url_ibge_cities = 'https://raw.githubusercontent.com/leogermani/estados-e-municipios-ibge/master/municipios.csv'\n",
    "df_ibge_cities = pd.read_csv(url_ibge_cities)\n",
    "df_ibge_cities.rename(columns={\n",
    "    'COD UF': 'COD_UF', \n",
    "    'COD': 'COD_MUN', \n",
    "    'NOME': 'NOME_MUN'\n",
    "}, inplace=True)\n",
    "df_ibge_cities = optimize_memory_usage(df_ibge_cities, print_log=False)\n",
    "url_ibge_states = 'https://raw.githubusercontent.com/leogermani/estados-e-municipios-ibge/master/estados.csv'\n",
    "df_ibge_states = pd.read_csv(url_ibge_states)\n",
    "df_ibge_states.rename(columns={\n",
    "    'COD': 'COD_UF', \n",
    "    'NOME': 'NOME_UF', \n",
    "    'SIGLA': 'SIGLA_UF'\n",
    "}, inplace=True)\n",
    "\n",
    "# --- 1.2.2 Preparando os \"Dicionários de Tradução\"\n",
    "\n",
    "print(\"\\nCriando dicionários de tradução para cidades e estados\")\n",
    "map_uf_code_to_name = pd.Series(df_ibge_states.NOME_UF.values, index=df_ibge_states.COD_UF).to_dict()\n",
    "map_uf_code_to_sigla = pd.Series(df_ibge_states.SIGLA_UF.values, index=df_ibge_states.COD_UF).to_dict()\n",
    "index_mun_6_digits = df_ibge_cities['COD_MUN'].astype(str).str[:6].astype(int) # capture apenas os 6 primeiros dígitos de COD_MUN\n",
    "map_mun_code_to_name = pd.Series(df_ibge_cities.NOME_MUN.values, index=index_mun_6_digits).to_dict()\n",
    "print(\"Dicionários criados.\")\n",
    "\n",
    "# --- 1.2.3 Preparando o df_sinasc e Aplicando o .map()\n",
    "print(\"\\nLimpando chaves do df_sinasc e aplicando .map() para enriquecer os dados\")\n",
    "codmunnasc_cleaned_str = df_sinasc['CODMUNNASC'].astype(str).str.extract('(\\\\d+)')[0].fillna('0') # Extrai apenas os dígitos\n",
    "codmunnasc_limpo_int = pd.to_numeric( codmunnasc_cleaned_str, errors='coerce').astype('Int64') # Converte para Int64, permitindo NaN\n",
    "cod_uf_nasc = pd.to_numeric(codmunnasc_cleaned_str.str[:2], errors='coerce').astype('Int64') # Extrai os 2 primeiros dígitos para COD_UF\n",
    "\n",
    "#Aplicando o mapeamento.\n",
    "df_sinasc['COD_UF_NASC'] = cod_uf_nasc\n",
    "df_sinasc['NOME_UF_NASC'] = df_sinasc['COD_UF_NASC'].map(map_uf_code_to_name)\n",
    "df_sinasc['SIGLA_UF_NASC'] = df_sinasc['COD_UF_NASC'].map(map_uf_code_to_sigla)\n",
    "df_sinasc['NOME_MUNIC_NASC'] = codmunnasc_limpo_int.map(map_mun_code_to_name)\n",
    "#Atualizando a coluna CODMUNNASC com a versão limpa\n",
    "df_sinasc['CODMUNNASC'] = codmunnasc_limpo_int\n",
    "\n",
    "df_sinasc_enriched = df_sinasc\n",
    "print(\"Enriquecimento e limpeza da CODMUNNASC concluído.\")\n",
    "display(df_sinasc_enriched.sample(10))\n",
    "\n",
    "#liberando memória\n",
    "del df_ibge_cities\n",
    "del df_ibge_states\n",
    "import gc\n",
    "gc.collect()\n",
    "print(\"\\nDataFrames auxiliares liberados da memória\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab10b23",
   "metadata": {},
   "source": [
    "## DIAGNÓSTICO: Análise das colunas DTNASC e DTNASCMAE antes da limpeza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- INICIANDO DIAGNÓSTICO DAS COLUNAS DE DATA ---\")\n",
    "\n",
    "df_diag = df_sinasc_enriched.copy()\n",
    "\n",
    "# 1 - VALIDAÇÃO DO ANO DE COLETA\n",
    "print(\"\\n--- Validando o Ano de Coleta ---\")\n",
    "valid_years = [2020, 2021, 2022]\n",
    "find_years = df_diag['ANO_COLETA'].unique()\n",
    "invalid_years = [year for year in find_years if year not in valid_years]\n",
    "\n",
    "if invalid_years:\n",
    "    print(f\"ALERTA: A coluna 'ANO_COLETA' contém anos inválidos: {invalid_years}\")\n",
    "    # Definimos nosso teto de realidade manualmente\n",
    "    ceiling_year = 2022\n",
    "else:\n",
    "    print(f\"OK: Todos os anos de coleta encontrados ({list(find_years)}) são válidos.\")\n",
    "    # Usamos o máximo dos dados, pois confiamos neles\n",
    "    ceiling_year = df_diag['ANO_COLETA'].max()\n",
    "    \n",
    "print(f\"==> Usando {ceiling_year} como o ano máximo de referência para a análise.\")\n",
    "\n",
    "date_cols_to_diagnose = ['DTNASC', 'DTNASCMAE']\n",
    "\n",
    "for col in date_cols_to_diagnose:\n",
    "    print(f\"\\n\\n---Análise da coluna: {col}---\")\n",
    "    # 2 - Analise de tipos e nulos\n",
    "    print(f\"Tipo de dado original: { df_diag[col].dtype}\")\n",
    "    null_count = df_diag[col].isnull().sum()\n",
    "    print(f\"Valores nulos (originais): { null_count} ({ null_count / len(df_diag):.2%})\") # Exibe a contagem e a porcentagem de valores nulos\n",
    "\n",
    "    # 3 - Analise do formato (após converter para string)\n",
    "    print(\"\\nAnálise de formato (Tamanho esperado da string 8 'DDMMAAAA')\")\n",
    "    series_str = df_diag[col].astype(str)\n",
    "    length_counts = series_str.str.len().value_counts().sort_index()\n",
    "    print(f\"Contagem de tamanhos de string: { length_counts}\")\n",
    "    \n",
    "    # Verificando conteúdo não-numérico\n",
    "    no_digit = series_str[~series_str.str.isdigit().fillna(False)] # Filtra valores que não são dígitos\n",
    "    if not no_digit.empty:\n",
    "        print(f\"\\nEncontrados {len(no_digit)} valores não numericos (estão 'sujos').\")\n",
    "        print(\"Exemplos de valores não numéricos\")\n",
    "        display(no_digit.value_counts().head())\n",
    "    else:\n",
    "        print(\"\\n Todos os valores (não nulos) são digitos. (estão 'limpos').\")\n",
    "\n",
    "    # 4 - Tentativa de conversão e análise de erros\n",
    "    series_dt = pd.to_datetime( series_str, format='%d%m%Y', errors='coerce') # Converte para datetime, valores inválidos viram NaT\n",
    "    count_convert_fails = series_dt.isnull().sum() # Conta quantos valores falharam na conversão\n",
    "    print(f\"\\n Após conversão para data (ddmmyyyy):\")\n",
    "    print(f\"Total falhas na conversão (NaT): { count_convert_fails } ({ count_convert_fails / len(df_diag):.2%})\") #\n",
    "\n",
    "    # 5 - Análise de intervalos (datas convertidas e plausíveis)\n",
    "    \n",
    "    valid_dates = series_dt.dropna()\n",
    "    if not valid_dates.empty:\n",
    "        print(f\"\\n Análise de intervalos das datas válidas:\")\n",
    "        print(f\"Data mínima: { valid_dates.min().date() }\")\n",
    "        print(f\"Data máxima: { valid_dates.max().date() }\")\n",
    "\n",
    "        #verificando datas futuras (dentro do contexto do DataFrame 2020-2022)\n",
    "        future_dates = valid_dates[valid_dates.dt.year > ceiling_year]\n",
    "\n",
    "        if not future_dates.empty:\n",
    "            print(f\"\\n ALERTA: Encontradas { len(future_dates) } datas posteriores ao último ano válido de coleta ({ceiling_year})!\")\n",
    "            print(\"Exemplos de datas futuras:\")\n",
    "            print(future_dates.value_counts().head())\n",
    "        \n",
    "        #verificando datas muito antigas (dentro do contexto do DataFrame 2020-2022)\n",
    "        old_dates = valid_dates[valid_dates.dt.year < 1920]\n",
    "        if not old_dates.empty:\n",
    "            print(f\"\\n ALERTA: Encontradas { len(old_dates) } datas anteriores a 1920!\")\n",
    "            print(\"Exemplos de datas muito antigas:\")\n",
    "            print(old_dates.value_counts().head())\n",
    "            \n",
    "print(\"\\n--- FIM DO DIAGNÓSTICO DAS COLUNAS DE DATA ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9eeb9f",
   "metadata": {},
   "source": [
    "## PARTE 2: PIPELINE DE LIMPEZA E ENGENHARIA DE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funções para etapas de limpeza e engenharia de features\n",
    "def clean_to_numeric(series):\n",
    "    \"\"\"\n",
    "    Converte uma série para numérico, extraindo apenas os dígitos.\n",
    "    \"\"\"\n",
    "    return pd.to_numeric(series.astype(str).str.extract('(\\\\d+)', expand=False), errors='coerce')\n",
    "\n",
    "def clean_to_datetime(series):\n",
    "    \"\"\"\n",
    "    Converte uma série para datetime, extraindo o formato 'DDMMAAAA'.\n",
    "    \"\"\"\n",
    "    return pd.to_datetime( series.astype(str).str.extract('( \\\\d{ 8})', expand=False), format='%d%m%Y', errors='coerce')\n",
    "\n",
    "def clean_to_categorical_code(series):\n",
    "    \"\"\"\n",
    "    Converte uma série para numérico, extraindo apenas o dígito único.\n",
    "    \"\"\"\n",
    "    cleaned_series = series.astype(str).str.extract('( \\\\d)', expand=False)\n",
    "    return pd.to_numeric(cleaned_series, errors='coerce')\n",
    "\n",
    "def calculate_age_manual(row):\n",
    "    \"\"\"\n",
    "    Calcula a idade da mãe no nascimento com base nas datas de nascimento.\n",
    "    \"\"\"\n",
    "    nasc_date, mae_nasc_date = row['DTNASC'], row['DTNASCMAE']\n",
    "    if pd.isna(nasc_date) or pd.isna(mae_nasc_date): return np.nan\n",
    "    age = nasc_date.year - mae_nasc_date.year # Calcula a diferença de anos\n",
    "    if (nasc_date.month, nasc_date.day) < (mae_nasc_date.month, mae_nasc_date.day): # Verifiqua se o aniversário já ocorreu no ano do nascimento\n",
    "        age -= 1 # Subtrai 1 se o aniversário ainda não ocorreu\n",
    "    return age"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
